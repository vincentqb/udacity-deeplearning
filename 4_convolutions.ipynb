{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4embtkV0pNxM"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 4\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb` and `3_regularization.ipynb`, we trained fully connected networks to classify [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) characters.\n",
    "\n",
    "The goal of this assignment is make the neural network convolutional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tm2CQN_Cpwj0"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "from time import clock\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11948,
     "status": "ok",
     "timestamp": 1446658914837,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "016b1a51-0290-4b08-efdb-8c95ffc3cd01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "- convolutions need the image data formatted as a cube (width by height by #channels)\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11952,
     "status": "ok",
     "timestamp": 1446658914857,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "650a208c-8359-4852-f4f5-8bf10e80ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28, 1) (200000, 10)\n",
      "Validation set (10000, 28, 28, 1) (10000, 10)\n",
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_channels = 1 # grayscale\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape(\n",
    "    (-1, image_size, image_size, num_channels)).astype(np.float32)\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "AgQDIREv02p1"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rhgjmROXu2O"
   },
   "source": [
    "Let's build a small network with two convolutional layers, followed by one fully connected layer. Convolutional networks are more expensive computationally, so we'll limit its depth and number of fully connected nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "IZYv70SvvOan"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.601196\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 1.663802\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 48.6%\n",
      "Minibatch loss at step 100: 1.052354\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 66.2%\n",
      "Minibatch loss at step 150: 0.283548\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.8%\n",
      "Minibatch loss at step 200: 0.162032\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.0%\n",
      "Minibatch loss at step 250: 0.933644\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 300: 1.106571\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 350: 0.813429\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 400: 0.314702\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 77.5%\n",
      "Minibatch loss at step 450: 0.495656\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 500: 0.889475\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 550: 0.570533\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 600: 0.391572\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 650: 0.511561\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 700: 0.518246\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 750: 0.594203\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 800: 0.463978\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 850: 0.659573\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 900: 0.573143\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.7%\n",
      "Minibatch loss at step 950: 0.469782\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 1000: 0.246880\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.8%\n",
      "Test accuracy: 89.1%\n",
      "Elapsed time: 99 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAEKCAYAAADpUNekAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJkiRJkiRJkiRll/8FwaKiC39LgKsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc237396160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "start = clock()\n",
    "loss_epoch = {}\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 50 == 0):      \n",
    "      # Collect loss over time to plot loss function\n",
    "      epoch = batch_size * step / train_labels.shape[0]\n",
    "      loss_epoch[epoch] = l\n",
    "            \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "# Print elapsed time\n",
    "print('Elapsed time: {:.0f} seconds.'.format(clock() - start))\n",
    "\n",
    "# Show loss function against epoch\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(list(loss_epoch.keys()), list(loss_epoch.values()))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Minibatch loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KedKkn4EutIK"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "The convolutional model above uses convolutions with stride 2 to reduce the dimensionality. Replace the strides by a max pooling operation (`nn.max_pool()`) of stride 2 and kernel size 2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    mpool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(mpool + layer1_biases)\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    mpool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(mpool + layer2_biases)\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
    "  \n",
    "  # Training computation.\n",
    "  logits = model(tf_train_dataset)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 3.324784\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 10.4%\n",
      "Minibatch loss at step 50: 1.793939\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 44.3%\n",
      "Minibatch loss at step 100: 1.094110\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 68.9%\n",
      "Minibatch loss at step 150: 0.332591\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 200: 0.186228\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 250: 0.961015\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 300: 1.344580\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 350: 0.847268\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 400: 0.484647\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 450: 0.436128\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 500: 1.040039\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 550: 0.378818\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 600: 0.320814\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 650: 0.553366\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 700: 0.516375\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 750: 0.395758\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.8%\n",
      "Minibatch loss at step 800: 0.416930\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 850: 0.758684\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 900: 0.364034\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 950: 0.397267\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.4%\n",
      "Minibatch loss at step 1000: 0.172500\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 83.9%\n",
      "Test accuracy: 90.0%\n",
      "Elapsed time: 362 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAEKCAYAAAALjMzdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuY8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc23426d940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "start = clock()\n",
    "loss_epoch = {}\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 50 == 0):      \n",
    "      # Collect loss over time to plot loss function\n",
    "      epoch = batch_size * step / train_labels.shape[0]\n",
    "      loss_epoch[epoch] = l\n",
    "            \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "# Print elapsed time\n",
    "print('Elapsed time: {:.0f} seconds.'.format(clock() - start))\n",
    "\n",
    "# Show loss function against epoch\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(list(loss_epoch.keys()), list(loss_epoch.values()))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Minibatch loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "klf21gpbAgb-"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a convolutional net. Look for example at the classic [LeNet5](http://yann.lecun.com/exdb/lenet/) architecture, adding Dropout, and/or adding learning rate decay.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# keep_prob = .8\n",
    "keep_prob = 1.\n",
    "\n",
    "# beta = 0.025\n",
    "beta = 0.\n",
    "\n",
    "batch_size = 16\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "\n",
    "num_hidden = 128\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data, keep_prob = None):\n",
    "        \n",
    "    if keep_prob is None:\n",
    "        flag = False\n",
    "        keep_prob = 1.\n",
    "    else:\n",
    "        flag = True\n",
    "    \n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    mpool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(mpool + layer1_biases)\n",
    "    \n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    mpool = tf.nn.max_pool(conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(mpool + layer2_biases)\n",
    "    \n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "        \n",
    "    layer3_weights_drop = tf.nn.dropout(layer3_weights, keep_prob)\n",
    "    layer4_weights_drop = tf.nn.dropout(layer4_weights, keep_prob)\n",
    "    \n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights_drop) + layer3_biases)\n",
    "    hidden = tf.matmul(hidden, layer4_weights_drop) + layer4_biases\n",
    "    \n",
    "    if flag:\n",
    "        return (hidden, layer3_weights, layer4_weights)\n",
    "    else:\n",
    "        return hidden\n",
    "  \n",
    "  # Training computation.\n",
    "  logits, layer3_weights, layer4_weights = model(tf_train_dataset, keep_prob)\n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "    \n",
    "  loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) \\\n",
    "       + 0.5 * beta * tf.nn.l2_loss(layer3_weights) \\\n",
    "       + 0.5 * beta * tf.nn.l2_loss(layer4_weights)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.04).minimize(loss)\n",
    "  # global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  # learning_rate = tf.train.exponential_decay(0.5, global_step, decay_steps = 1000, decay_rate = 0.90)\n",
    "  # optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  # optimizer = tf.train.AdagradOptimizer(0.025).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
    "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 4.489192\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 10.0%\n",
      "Minibatch loss at step 50: 1.167833\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 62.6%\n",
      "Minibatch loss at step 100: 0.876214\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 72.9%\n",
      "Minibatch loss at step 150: 0.306983\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 200: 0.149472\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 250: 1.141812\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 77.7%\n",
      "Minibatch loss at step 300: 1.270846\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 350: 0.759028\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 400: 0.325877\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 450: 0.454523\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 500: 0.933788\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 82.8%\n",
      "Minibatch loss at step 550: 0.748388\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 600: 0.293136\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.7%\n",
      "Minibatch loss at step 650: 0.522881\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 700: 0.533186\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 750: 0.347966\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.3%\n",
      "Minibatch loss at step 800: 0.396087\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 850: 0.705089\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 900: 0.546597\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 950: 0.501567\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1000: 0.169568\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 84.1%\n",
      "Minibatch loss at step 1050: 0.184812\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.3%\n",
      "Minibatch loss at step 1100: 0.293422\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 1150: 0.399221\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 1200: 0.364499\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1250: 0.523475\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.7%\n",
      "Minibatch loss at step 1300: 0.714559\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.9%\n",
      "Minibatch loss at step 1350: 0.296815\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 1400: 0.452530\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.4%\n",
      "Minibatch loss at step 1450: 0.207087\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1500: 0.423921\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.2%\n",
      "Minibatch loss at step 1550: 0.449860\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1600: 0.873941\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 1650: 0.452327\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 1700: 0.686873\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 1750: 0.389543\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 1800: 0.710227\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 1850: 0.744174\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 1900: 0.590147\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 1950: 0.580308\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 2000: 0.434635\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 2050: 0.149510\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 2100: 0.866391\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 2150: 0.592414\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2200: 0.258883\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2250: 0.298052\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 2300: 0.612778\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 2350: 1.030643\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.5%\n",
      "Minibatch loss at step 2400: 0.374021\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2450: 0.434070\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 2500: 0.267271\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 2550: 0.546916\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2600: 0.744064\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 2650: 0.265283\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.5%\n",
      "Minibatch loss at step 2700: 0.136664\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 86.3%\n",
      "Minibatch loss at step 2750: 0.291013\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Minibatch loss at step 2800: 0.482677\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 2850: 0.871168\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 2900: 0.480016\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 2950: 0.491452\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3000: 0.299424\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3050: 0.327068\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3100: 0.060061\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.0%\n",
      "Minibatch loss at step 3150: 0.037698\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3200: 0.221532\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3250: 0.870494\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 3300: 0.466001\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3350: 0.106257\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 3400: 0.352645\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3450: 0.090863\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3500: 0.101443\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 3550: 0.773265\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.1%\n",
      "Minibatch loss at step 3600: 0.488060\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3650: 0.600693\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 3700: 1.107528\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 3750: 0.887096\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.4%\n",
      "Minibatch loss at step 3800: 0.347985\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 3850: 0.253000\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3900: 0.713239\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.1%\n",
      "Minibatch loss at step 3950: 0.098574\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4000: 0.427789\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4050: 0.422945\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4100: 0.585779\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4150: 0.124889\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.6%\n",
      "Minibatch loss at step 4200: 0.441885\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4250: 0.656259\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4300: 0.431960\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 4350: 0.029498\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4400: 0.605811\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 4450: 0.493117\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Minibatch loss at step 4500: 0.580376\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 4550: 0.534333\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4600: 0.401384\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4650: 0.762046\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 4700: 0.250029\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 4750: 0.672103\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4800: 0.234813\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4850: 0.402338\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 4900: 0.205942\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 4950: 0.569014\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5000: 0.550150\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5050: 0.308111\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5100: 0.580961\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 5150: 0.088913\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5200: 0.493994\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5250: 1.147440\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5300: 0.712307\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5350: 0.597066\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5400: 0.218125\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.8%\n",
      "Minibatch loss at step 5450: 0.175183\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5500: 0.545415\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5550: 0.267154\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.4%\n",
      "Minibatch loss at step 5600: 0.133682\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 5650: 0.191983\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5700: 0.276028\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5750: 0.459950\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 88.7%\n",
      "Minibatch loss at step 5800: 0.150367\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5850: 0.201985\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 5900: 0.209716\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 5950: 0.303701\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 6000: 0.140435\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 93.7%\n",
      "Elapsed time: 2130 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/matplotlib/collections.py:549: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == 'face':\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEKCAYAAAD+ckdtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2342b9208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_steps = 6001\n",
    "\n",
    "start = clock()\n",
    "loss_epoch = {}\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if (step % 50 == 0):      \n",
    "      # Collect loss over time to plot loss function\n",
    "      epoch = batch_size * step / train_labels.shape[0]\n",
    "      loss_epoch[epoch] = l\n",
    "            \n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))\n",
    "\n",
    "# Print elapsed time\n",
    "print('Elapsed time: {:.0f} seconds.'.format(clock() - start))\n",
    "\n",
    "# Show loss function against epoch\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(list(loss_epoch.keys()), list(loss_epoch.values()))\n",
    "plt.yscale('log')\n",
    "plt.ylabel('Minibatch loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "4_convolutions.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
